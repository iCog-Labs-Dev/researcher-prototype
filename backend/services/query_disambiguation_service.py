import asyncio
from typing import Dict, Any
from datetime import datetime

from nodes.base import (
    logger,
    config,
    get_current_datetime_str,
    ChatOpenAI,
    SystemMessage,
    HumanMessage,
    QUERY_DISAMBIGUATION_SYSTEM_PROMPT
)
from models import (
    QueryDisambiguationAnalysis,
    ClarifyingQuestion,
    QueryRefinement
)


class QueryDisambiguationService:
    """Service for analyzing query vagueness and generating clarifying questions using LLM."""
    
    async def analyze_query(self, query: str, context: Dict[str, Any]) -> QueryDisambiguationAnalysis:
        logger.info(f"Query Disambiguation: analyzing '{query[:50]}...'")
        try:
            analysis = await self._llm_analyze_query(query, context)
            logger.info(f"LLM analysis complete - vague: {analysis.is_vague}, confidence: {analysis.confidence_score:.2f}")
            return analysis
        except Exception as e:
            logger.error(f"Error in LLM analysis: {str(e)}")
            return QueryDisambiguationAnalysis(
                is_vague=False,
                confidence_score=0.0,
                vague_indicators=[],
                clarifying_questions=[],
                suggested_refinements=[],
                context_analysis=f"LLM analysis failed: {str(e)}"
            )

    async def _llm_analyze_query(self, query: str, context: Dict[str, Any]) -> QueryDisambiguationAnalysis:
        llm = ChatOpenAI(
            model=config.ROUTER_MODEL,
            temperature=0.1,
            max_tokens=500,
            api_key=config.OPENAI_API_KEY
        )

        conversation_context = self._build_conversation_context(context)
        memory_context = context.get("memory_context", "")

        system_prompt = QUERY_DISAMBIGUATION_SYSTEM_PROMPT.format(
            current_time=get_current_datetime_str(),
            memory_context_section=f"CONVERSATION MEMORY:\n{memory_context}\n\n" if memory_context else ""
        )

        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=f"QUERY TO ANALYZE: {query}\n\nCONVERSATION CONTEXT:\n{conversation_context}")
        ]

        response = await llm.ainvoke(messages)
        return self._parse_llm_response(response.content, query, context)

    def _build_conversation_context(self, context: Dict[str, Any]) -> str:
        messages = context.get("messages", [])
        if not messages:
            return "No previous conversation context."
        recent_messages = messages[-3:]
        context_lines = [
            f"{'User' if msg.role == 'user' else 'Assistant'}: {msg.content}"
            for msg in recent_messages if hasattr(msg, "content")
        ]
        return "\n".join(context_lines) if context_lines else "No recent conversation context."

    def _parse_llm_response(self, llm_response: str, query: str, context: Dict[str, Any]) -> QueryDisambiguationAnalysis:
        try:
            lines = [line.strip() for line in llm_response.split("\n") if line.strip()]
            is_vague = False
            confidence_score = 0.0
            vague_indicators, clarifying_questions, suggested_refinements = [], [], []
            context_analysis = ""
            current_section = None

            for line in lines:
                upper = line.upper()
                if "VAGUE:" in upper or "IS_VAGUE:" in upper:
                    is_vague = "true" in line.lower() or "yes" in line.lower()
                elif "CONFIDENCE:" in upper:
                    try:
                        confidence_score = float(line.split(":")[1].strip())
                    except:
                        confidence_score = 0.5 if is_vague else 0.0
                elif "INDICATORS:" in upper:
                    current_section = "indicators"
                elif "QUESTIONS:" in upper:
                    current_section = "questions"
                elif "SUGGESTIONS:" in upper:
                    current_section = "suggestions"
                elif "CONTEXT:" in upper:
                    current_section = "context"
                elif line.startswith(("-", "â€¢")):
                    item = line[1:].strip()
                    if current_section == "indicators":
                        vague_indicators.append(item)
                    elif current_section == "questions":
                        clarifying_questions.append(ClarifyingQuestion(
                            question=item,
                            question_type="open_ended",
                            context="Generated by LLM"
                        ))
                    elif current_section == "suggestions":
                        suggested_refinements.append(item)
                elif current_section == "context":
                    context_analysis += line + " "

            if not vague_indicators and is_vague:
                vague_indicators = ["LLM detected vagueness"]

            if not clarifying_questions and is_vague:
                clarifying_questions = [ClarifyingQuestion(
                    question="Could you provide more specific details about what you're looking for?",
                    question_type="open_ended",
                    context="LLM-generated clarification request"
                )]

            if not suggested_refinements:
                suggested_refinements = [f"{query} with more specific details"]

            return QueryDisambiguationAnalysis(
                is_vague=is_vague,
                confidence_score=confidence_score,
                vague_indicators=vague_indicators,
                clarifying_questions=clarifying_questions,
                suggested_refinements=suggested_refinements,
                context_analysis=context_analysis.strip() or "LLM analysis completed"
            )
        except Exception as e:
            logger.error(f"Error parsing LLM response: {str(e)}")
            return QueryDisambiguationAnalysis(
                is_vague=False,
                confidence_score=0.0,
                vague_indicators=[],
                clarifying_questions=[],
                suggested_refinements=[],
                context_analysis=f"Error parsing LLM response: {str(e)}"
            )

    async def refine_query_with_clarification(self, original_query: str, clarification: str, context: Dict[str, Any]) -> QueryRefinement:
        try:
            refined_query = self._clean_query(f"{original_query} {clarification}".strip())
            return QueryRefinement(
                original_query=original_query,
                refined_query=refined_query,
                refinement_type="clarification",
                confidence_score=0.8,
                reasoning=f"Combined original query with user clarification: '{clarification}'"
            )
        except Exception as e:
            logger.error(f"Error refining query: {str(e)}")
            return QueryRefinement(
                original_query=original_query,
                refined_query=original_query,
                refinement_type="clarification",
                confidence_score=0.0,
                reasoning=f"Error in refinement: {str(e)}"
            )

    def _clean_query(self, query: str) -> str:
        query = " ".join(query.split())
        filler_words = ["please", "can you", "could you", "i need", "i want"]
        for filler in filler_words:
            query = query.replace(filler, "").strip()
        return query
